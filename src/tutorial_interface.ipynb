{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML2 Group 3 Interface Tutorial\n",
    "\n",
    "\"_THIS WILL MAKE SENSE LATER, I PROMISE_\"\n",
    "\n",
    "-Reed\n",
    "\n",
    "## First Do Some Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_mgmt.RecSysData as rsd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Up the Dataset Class\n",
    "\n",
    "Note above that we had the following line:\n",
    "> `import data_mgmt.RecSysData as rsd`\n",
    "\n",
    "So, what they heck was going on there?\n",
    "\n",
    "Well, if you check out /src/data_mgmt/RecSysData.py, you can see what exactly is going on.\n",
    "\n",
    "The first non-import line will look like this:\n",
    "> `class RecSysData(BaseDataClass.BaseDataClass):`\n",
    "\n",
    "Which is creating a Python class based on something else (i.e. a 'child'), a \"BaseDataClass\". Conveniently the BaseDataClass lives in /src/data_mgmt/BaseDataClass.py. If we open that, we see this:\n",
    "\n",
    "> `class BaseDataClass(Dataset):`\n",
    "\n",
    "Indicating that a BaseDataClass is a child of the Dataset class, which is built into PyTorch to help keep your data organized.\n",
    "\n",
    "**We'll go into why this is a good / cool thing worth our hassle a little later. For now let's load up a RecSysData.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppath=\"..\\\\data\\\\\"\n",
    "\n",
    "# The minimum argument RecSysData needs to create obj is the data path\n",
    "tt = rsd.RecSysData(ppath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That may have taken a minute or two if you had to go from a .json.gz to a .csv, but don't worry. It saves the .csv after the first iteration to make repeated object creation go faster.\n",
    "\n",
    "We don't just upload / use the .csv to git because it's 5x the size of the .json.gz\n",
    "\n",
    "Let's look at the contents of tt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_data',\n",
       " 'transform',\n",
       " 'target_transform',\n",
       " 'preprocess',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " 'recSysPreprocessing',\n",
       " 'recSysXfrm',\n",
       " 'recSysTgtXfrm']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.__dir__()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transform`, `target_transform`, and `preprocess` are all functions, not just variables. We'll get to those later.\n",
    "\n",
    "`df_data` is a dataframe loaded up with the contents of train.json.gz similarly to the output of \"group4_base_data_clean.ipynb\". HOWEVER - it has been pruned specifically for the Reccomender System challenge.\n",
    "\n",
    "See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>uid</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R798569390</td>\n",
       "      <td>U490934656</td>\n",
       "      <td>1380153600</td>\n",
       "      <td>I402344648</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R436443063</td>\n",
       "      <td>U714157797</td>\n",
       "      <td>1360195200</td>\n",
       "      <td>I697650540</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R103439446</td>\n",
       "      <td>U507366950</td>\n",
       "      <td>1394928000</td>\n",
       "      <td>I464613034</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R486351639</td>\n",
       "      <td>U307862152</td>\n",
       "      <td>1394409600</td>\n",
       "      <td>I559560885</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R508664275</td>\n",
       "      <td>U742726598</td>\n",
       "      <td>1375142400</td>\n",
       "      <td>I476005312</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewHash  reviewerID  unixReviewTime      itemID  rating  uid  pid\n",
       "0  R798569390  U490934656      1380153600  I402344648     4.0    0    0\n",
       "1  R436443063  U714157797      1360195200  I697650540     4.0    1    1\n",
       "2  R103439446  U507366950      1394928000  I464613034     5.0    2    2\n",
       "3  R486351639  U307862152      1394409600  I559560885     2.0    3    3\n",
       "4  R508664275  U742726598      1375142400  I476005312     5.0    4    4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are (39239,) unique users and...\n",
      "There are (19914,) unique products out of ...\n",
      "A total of (200000, 7) records in the training dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {tt.df_data.uid.unique().shape} unique users and...\")\n",
    "print(f\"There are {tt.df_data.pid.unique().shape} unique products out of ...\")\n",
    "print(f\"A total of {tt.df_data.shape} records in the training dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STOP!**\n",
    "\n",
    "*We don't work with this dataframe. At all. Ever.*\n",
    "\n",
    "`tt` can be interacted with just like an array. Just like this:\n",
    "\n",
    "> `tt[idx]`\n",
    "\n",
    "Right now it doesn't work with slices (e.g. `tt[3:8]`), I'm working on if that's a bad thing or not, but for right now I think it's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 4], dtype=torch.int32), tensor(5.))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `tt` also responds to the `len` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok so WTF are we witnessing?\n",
    "\n",
    "The whole point of the Dataset class is to overload 3 methods:\n",
    "`__init__`, `__len__`, and `__getitem__`.\n",
    "\n",
    "If you do this proficiently that now means the Dataset class will make your data play very nicely with a PyTorch dataloader, which is the basis of datahandling within training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(tt, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature user index and item index: 23437,6260\n",
      "Labels batch shape: 3.0\n",
      "Feature user index and item index: 1249,1174\n",
      "Labels batch shape: 5.0\n",
      "Feature user index and item index: 24992,5613\n",
      "Labels batch shape: 3.0\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "for i in range(3): \n",
    "    print(f\"Feature user index and item index: {train_features[i][0]},{train_features[i][1]}\")\n",
    "    print(f\"Labels batch shape: {train_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23437,  6260],\n",
       "        [ 1249,  1174],\n",
       "        [24992,  5613],\n",
       "        [25087, 10794]], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 5., 3., 3.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note as well that the features and labels outputs are already PyTorch tensors and thus ready to get thrown at a PyTorch model. This conversion takes place within the `__getitem__` function. If the Dataset class has `transform` and `transform_target` methods defined then `__getitem__` won't just return the row - it will use `transform` to get the feature vector and `transform_target` to get the label/target scalar (or vector).\n",
    "\n",
    "Looking back at the result of `tt.df_data.head()` you'll also note the results were a little paired down already versus the dataframe Jamie originally printed. This is because at object creation the `RecSysData` class executes its `preprocess` function to drop unnecessary columns and generated derived columns.\n",
    "\n",
    "*All of this is 100% customizable*\n",
    "\n",
    "Additionally, I've written it so that substituting your own is easy. Check this out:\n",
    "\n",
    "## Customizing your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overloadedPreProcess(df_data):\n",
    "    df_data['uid'], _ = pd.factorize(df_data['reviewerID'])\n",
    "    df_data['pid'], _ = pd.factorize(df_data['itemID'])\n",
    "    \n",
    "    df_data = df_data[['reviewHash', 'reviewerID', \n",
    "                    'unixReviewTime', 'itemID', \n",
    "                    'rating', 'uid','pid','summaryCharacterLength']]\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "def overloadedTransform(in_row):        \n",
    "    return torch.tensor([in_row.uid,in_row.pid,in_row.summaryCharacterLength],dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = rsd.RecSysData(ppath, preprocess=overloadedPreProcess, transform=overloadedTransform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined two new functions: `overloadedPreProcess` and `overloadedTransform`.\n",
    "\n",
    "These are passed to `RecSysData` at object creation.\n",
    "\n",
    "Look at the output now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature user index and item index: 33351,6769\n",
      "Labels batch shape: 5.0\n",
      "Feature user index and item index: 22282,3455\n",
      "Labels batch shape: 5.0\n",
      "Feature user index and item index: 27669,17472\n",
      "Labels batch shape: 5.0\n"
     ]
    }
   ],
   "source": [
    "train_loader2 = DataLoader(test2, batch_size=4, shuffle=True)\n",
    "\n",
    "train_features2, train_labels2 = next(iter(train_loader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33351,  6769,    27],\n",
       "        [22282,  3455,     9],\n",
       "        [27669, 17472,     4],\n",
       "        [ 5473,  4204,     7]], dtype=torch.int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That third column is `summaryCharacterLength` which was preserved instead of dropped by telling the Dataset class to do so in both the preprocessor and transform function.\n",
    "\n",
    "\n",
    "## CONCLUSION!\n",
    "\n",
    "So, the big takeaways from this are as follows:\n",
    "1. Datasets are a good way to load / interact with your data when using PyTorch because they...\n",
    "1. Play nice by default with DataLoaders, which means...\n",
    "1. Less frustration in setting up / shaping your model inputs because...\n",
    "1. You're in control of the shape/size instead of relying on built in functions to do it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
