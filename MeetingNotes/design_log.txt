## Batch 1
## Testing latent features
["convtest1", 128, 0.0005, 1e-3, 10, 'adamw', (4,(256,256),(48, 48, 48))]
["convtest2", 128, 0.0005, 1e-3, 10, 'adamw', (8,(256,256),(48, 48, 48))]
["convtest3", 128, 0.0005, 1e-3, 10, 'adamw', (16,(256,256),(48, 48, 48))]
["convtest4", 128, 0.0005, 1e-3, 10, 'adamw', (32,(256,256),(48, 48, 48))]
["convtest5", 128, 0.0005, 1e-3, 10, 'adamw', (64,(256,256),(48, 48, 48))] ** Best
["convtest6", 128, 0.0005, 1e-3, 10, 'adamw', (128,(256,256),(48, 48, 48))] ** Overfit begins
["convtest7", 128, 0.0005, 1e-3, 10, 'adamw', (256,(256,256),(48, 48, 48))] 


## Batch 2
## Testing MLP layer depth and # nodes
## All data was still fairly noisy in training, batch size too small?
["convtest8", 128, 0.0005, 1e-3, 10, 'adamw', (32,(8,8),(48, 48, 48))],
["convtest9", 128, 0.0005, 1e-3, 10, 'adamw', (64,(8,8),(48, 48, 48))],
["convtest10", 128, 0.0005, 1e-3, 10, 'adamw', (128,(8,8),(48, 48, 48))], **
["convtest11", 128, 0.0005, 1e-3, 10, 'adamw', (32,(8,8,8),(48, 48, 48))],
["convtest12", 128, 0.0005, 1e-3, 10, 'adamw', (64,(8,8,8),(48, 48, 48))],
["convtest13", 128, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8),(48, 48, 48))],
["convtest14", 128, 0.0005, 1e-3, 10, 'adamw', (32,(8,8,8,8),(48, 48, 48))],
["convtest15", 128, 0.0005, 1e-3, 10, 'adamw', (64,(8,8,8,8),(48, 48, 48))],
["convtest16", 128, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))], ** Best
["convtest17", 128, 0.0005, 1e-3, 10, 'adamw', (32,(16,16),(48, 48, 48))],
["convtest18", 128, 0.0005, 1e-3, 10, 'adamw', (64,(16,16),(48, 48, 48))],
["convtest19", 128, 0.0005, 1e-3, 10, 'adamw', (128,(16,16),(48, 48, 48))],
["convtest20", 128, 0.0005, 1e-3, 10, 'adamw', (32,(16,16,16),(48, 48, 48))],
["convtest21", 128, 0.0005, 1e-3, 10, 'adamw', (64,(16,16,16),(48, 48, 48))],
["convtest22", 128, 0.0005, 1e-3, 10, 'adamw', (128,(16,16,16),(48, 48, 48))],
["convtest23", 128, 0.0005, 1e-3, 10, 'adamw', (32,(16,16,16,16),(48, 48, 48))],
["convtest24", 128, 0.0005, 1e-3, 10, 'adamw', (64,(16,16,16,16),(48, 48, 48))],
["convtest25", 128, 0.0005, 1e-3, 10, 'adamw', (128,(16,16,16,16),(48, 48, 48))],
["convtest26", 128, 0.0005, 1e-3, 10, 'adamw', (32,(32,32),(48, 48, 48))],
["convtest27", 128, 0.0005, 1e-3, 10, 'adamw', (64,(32,32),(48, 48, 48))],
["convtest28", 128, 0.0005, 1e-3, 10, 'adamw', (128,(32,32),(48, 48, 48))],
["convtest29", 128, 0.0005, 1e-3, 10, 'adamw', (32,(32,32,32),(48, 48, 48))],
["convtest30", 128, 0.0005, 1e-3, 10, 'adamw', (64,(32,32,32),(48, 48, 48))],
["convtest31", 128, 0.0005, 1e-3, 10, 'adamw', (128,(32,32,32),(48, 48, 48))],
["convtest32", 128, 0.0005, 1e-3, 10, 'adamw', (32,(32,32,32,32),(48, 48, 48))],
["convtest33", 128, 0.0005, 1e-3, 10, 'adamw', (64,(32,32,32,32),(48, 48, 48))],
["convtest34", 128, 0.0005, 1e-3, 10, 'adamw', (128,(32,32,32,32),(48, 48, 48))]


## Batch 3
## Experiment with Bath Size Before Depth
## So looks like 512 is our champion?
["batch_001", 256, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))]
["batch_002", 512, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))] ** Best
["batch_003", 1024, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))]
["batch_004", 2048, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))]
["batch_005", 4096, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))]
["batch_006", 64, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))]
["batch_007", 32, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))]
["batch_008", 16, 0.0005, 1e-3, 10, 'adamw', (128,(8,8,8,8),(48, 48, 48))]


## Batch 4
## Experiment with 8-wide MLP depth
# Actually dropped the weight decay a lot because weights are proportional to depth
["depth_001", 512, 0.0005, 1e-3, 25, 'adamw', (128, 1*(8,8),(48, 48, 48))],
["depth_002", 512, 0.0005, 1e-3, 25, 'adamw', (128, 2*(8,8),(48, 48, 48))],
["depth_003", 512, 0.0005, 1e-3, 25, 'adamw', (128, 3*(8,8),(48, 48, 48))],
["depth_004", 512, 0.0005, 1e-3, 25, 'adamw', (128, 4*(8,8),(48, 48, 48))],
["depth_005", 512, 0.0005, 1e-3, 25, 'adamw', (128, 5*(8,8),(48, 48, 48))],
["depth_006", 512, 0.0005, 1e-3, 25, 'adamw', (128, 6*(8,8),(48, 48, 48))],
["depth_007", 512, 0.0005, 1e-3, 25, 'adamw', (128, 7*(8,8),(48, 48, 48))],
["depth_008", 512, 0.0005, 1e-3, 25, 'adamw', (128, 8*(8,8),(48, 48, 48))],
["depth_009", 512, 0.0005, 1e-3, 25, 'adamw', (128, 9*(8,8),(48, 48, 48))],
["depth_010", 512, 0.0005, 1e-3, 25, 'adamw', (128,10*(8,8),(48, 48, 48))],
["depth_011", 512, 0.0005, 1e-2, 25, 'adamw', (128, 1*(8,8),(48, 48, 48))],
["depth_012", 512, 0.0005, 1e-2, 25, 'adamw', (128, 2*(8,8),(48, 48, 48))],
["depth_013", 512, 0.0005, 1e-2, 25, 'adamw', (128, 3*(8,8),(48, 48, 48))],
["depth_014", 512, 0.0005, 1e-2, 25, 'adamw', (128, 4*(8,8),(48, 48, 48))],
["depth_015", 512, 0.0005, 1e-2, 25, 'adamw', (128, 5*(8,8),(48, 48, 48))],
["depth_016", 512, 0.0005, 1e-2, 25, 'adamw', (128, 6*(8,8),(48, 48, 48))],
["depth_017", 512, 0.0005, 1e-2, 25, 'adamw', (128, 7*(8,8),(48, 48, 48))],** Best
["depth_018", 512, 0.0005, 1e-2, 25, 'adamw', (128, 8*(8,8),(48, 48, 48))],
["depth_019", 512, 0.0005, 1e-2, 25, 'adamw', (128, 9*(8,8),(48, 48, 48))],
["depth_020", 512, 0.0005, 1e-2, 25, 'adamw', (128,10*(8,8),(48, 48, 48))]


## Batch 5
## Blending in CIN depths now
## Seems like even at e-5 wd some of the deeper networks were not mapping
# Conclusions -> Deeper is better
# Largest front end you can get is better (to carry info ro the MLP/CIP)
# Need a looooooooow regularization term as your number of factors increases

["depth_101", 512, 0.0005, 1e-5, 25, 'adamw', (128, 7*(8,8),(48, 48, 48))],
["depth_002", 512, 0.0005, 1e-6, 25, 'adamw', (128, 7*(8,8),(48, 48, 48))],
["depth_003", 512, 0.0005, 1e-7, 25, 'adamw', (128, 7*(8,8),(48, 48, 48))],
["depth_004", 512, 0.0005, 1e-8, 25, 'adamw', (128, 7*(8,8),(48, 48, 48))],
["depth_005", 512, 0.0005, 1e-9, 25, 'adamw', (128, 7*(8,8),(48, 48, 48))],
["depth_006", 512, 0.0005, 1e-5, 25, 'adamw', (256, 7*(8,8),(48, 48, 48))],
["depth_007", 512, 0.0005, 1e-6, 25, 'adamw', (256, 7*(8,8),(48, 48, 48))],
["depth_008", 512, 0.0005, 1e-7, 25, 'adamw', (256, 7*(8,8),(48, 48, 48))],
["depth_009", 512, 0.0005, 1e-8, 25, 'adamw', (256, 7*(8,8),(48, 48, 48))],
["depth_010", 512, 0.0005, 1e-9, 25, 'adamw', (256, 7*(8,8),(48, 48, 48))],
["depth_011", 512, 0.0005, 1e-5, 25, 'adamw', (512, 7*(8,8),(48, 48, 48))],
["depth_012", 512, 0.0005, 1e-6, 25, 'adamw', (512, 7*(8,8),(48, 48, 48))],
["depth_013", 512, 0.0005, 1e-7, 25, 'adamw', (512, 7*(8,8),(48, 48, 48))],
["depth_014", 512, 0.0005, 1e-8, 25, 'adamw', (512, 7*(8,8),(48, 48, 48))],
["depth_015", 512, 0.0005, 1e-9, 25, 'adamw', (512, 7*(8,8),(48, 48, 48))],
["depth_201", 512, 0.0005, 1e-5, 25, 'adamw', (128, 7*(8,8),(24,24,24))],
["depth_202", 512, 0.0005, 1e-6, 25, 'adamw', (128, 7*(8,8),(24,24,24))],
["depth_203", 512, 0.0005, 1e-7, 25, 'adamw', (128, 7*(8,8),(24,24,24))],
["depth_204", 512, 0.0005, 1e-8, 25, 'adamw', (128, 7*(8,8),(24,24,24))],
["depth_205", 512, 0.0005, 1e-9, 25, 'adamw', (128, 7*(8,8),(24,24,24))],
["depth_206", 512, 0.0005, 1e-5, 25, 'adamw', (256, 7*(8,8),(24,24,24))],
["depth_207", 512, 0.0005, 1e-6, 25, 'adamw', (256, 7*(8,8),(24,24,24))],
["depth_208", 512, 0.0005, 1e-7, 25, 'adamw', (256, 7*(8,8),(24,24,24))],
["depth_209", 512, 0.0005, 1e-8, 25, 'adamw', (256, 7*(8,8),(24,24,24))],
["depth_210", 512, 0.0005, 1e-9, 25, 'adamw', (256, 7*(8,8),(24,24,24))],
["depth_211", 512, 0.0005, 1e-5, 25, 'adamw', (512, 7*(8,8),(24,24,24))],
["depth_212", 512, 0.0005, 1e-6, 25, 'adamw', (512, 7*(8,8),(24,24,24))],
["depth_213", 512, 0.0005, 1e-7, 25, 'adamw', (512, 7*(8,8),(24,24,24))],
["depth_214", 512, 0.0005, 1e-8, 25, 'adamw', (512, 7*(8,8),(24,24,24))],
["depth_215", 512, 0.0005, 1e-9, 25, 'adamw', (512, 7*(8,8),(24,24,24))],
["depth_301", 512, 0.0005, 1e-5, 25, 'adamw', (128, 7*(8,8),(72,72,72))],
["depth_302", 512, 0.0005, 1e-6, 25, 'adamw', (128, 7*(8,8),(72,72,72))],
["depth_303", 512, 0.0005, 1e-7, 25, 'adamw', (128, 7*(8,8),(72,72,72))],
["depth_304", 512, 0.0005, 1e-8, 25, 'adamw', (128, 7*(8,8),(72,72,72))],
["depth_305", 512, 0.0005, 1e-9, 25, 'adamw', (128, 7*(8,8),(72,72,72))],
["depth_306", 512, 0.0005, 1e-5, 25, 'adamw', (256, 7*(8,8),(72,72,72))],
["depth_307", 512, 0.0005, 1e-6, 25, 'adamw', (256, 7*(8,8),(72,72,72))],
["depth_308", 512, 0.0005, 1e-7, 25, 'adamw', (256, 7*(8,8),(72,72,72))],
["depth_309", 512, 0.0005, 1e-8, 25, 'adamw', (256, 7*(8,8),(72,72,72))],
["depth_310", 512, 0.0005, 1e-9, 25, 'adamw', (256, 7*(8,8),(72,72,72))],
["depth_311", 512, 0.0005, 1e-5, 25, 'adamw', (512, 7*(8,8),(72,72,72))],
["depth_312", 512, 0.0005, 1e-6, 25, 'adamw', (512, 7*(8,8),(72,72,72))],
["depth_313", 512, 0.0005, 1e-7, 25, 'adamw', (512, 7*(8,8),(72,72,72))],
["depth_314", 512, 0.0005, 1e-8, 25, 'adamw', (512, 7*(8,8),(72,72,72))],
["depth_315", 512, 0.0005, 1e-9, 25, 'adamw', (512, 7*(8,8),(72,72,72))],
["depth_401", 512, 0.0005, 1e-5, 25, 'adamw', (128, 7*(8,8),(24,24,24,24))],
["depth_402", 512, 0.0005, 1e-6, 25, 'adamw', (128, 7*(8,8),(24,24,24,24))],
["depth_403", 512, 0.0005, 1e-7, 25, 'adamw', (128, 7*(8,8),(24,24,24,24))],
["depth_404", 512, 0.0005, 1e-8, 25, 'adamw', (128, 7*(8,8),(24,24,24,24))],
["depth_405", 512, 0.0005, 1e-9, 25, 'adamw', (128, 7*(8,8),(24,24,24,24))],
["depth_406", 512, 0.0005, 1e-5, 25, 'adamw', (256, 7*(8,8),(24,24,24,24))],
["depth_407", 512, 0.0005, 1e-6, 25, 'adamw', (256, 7*(8,8),(24,24,24,24))],
["depth_408", 512, 0.0005, 1e-7, 25, 'adamw', (256, 7*(8,8),(24,24,24,24))],
["depth_409", 512, 0.0005, 1e-8, 25, 'adamw', (256, 7*(8,8),(24,24,24,24))],
["depth_410", 512, 0.0005, 1e-9, 25, 'adamw', (256, 7*(8,8),(24,24,24,24))],
["depth_411", 512, 0.0005, 1e-5, 25, 'adamw', (512, 7*(8,8),(24,24,24,24))],
["depth_412", 512, 0.0005, 1e-6, 25, 'adamw', (512, 7*(8,8),(24,24,24,24))],
["depth_413", 512, 0.0005, 1e-7, 25, 'adamw', (512, 7*(8,8),(24,24,24,24))],
["depth_414", 512, 0.0005, 1e-8, 25, 'adamw', (512, 7*(8,8),(24,24,24,24))],
["depth_415", 512, 0.0005, 1e-9, 25, 'adamw', (512, 7*(8,8),(24,24,24,24))]


# Problematic - started running out of memory
["depth_501", 512, 0.0005, 1e-15, 25, 'adamw', (1024, 8*(8,8),4*(96))]
["depth_502", 512, 0.0005, 1e-15, 25, 'adamw', (2048, 8*(8,8),4*(96))]
["depth_503", 512, 0.0005, 1e-15, 25, 'adamw', (4096, 8*(8,8),4*(96))]
["depth_504", 512, 0.0005, 1e-15, 25, 'adamw', (1024, 8*(8,8),5*(96))]
["depth_505", 512, 0.0005, 1e-15, 25, 'adamw', (2048, 8*(8,8),5*(96))]
["depth_506", 512, 0.0005, 1e-15, 25, 'adamw', (4096, 8*(8,8),5*(96))]
["depth_507", 512, 0.0005, 1e-15, 25, 'adamw', (1024, 8*(8,8),6*(96))]
["depth_508", 512, 0.0005, 1e-15, 25, 'adamw', (2048, 8*(8,8),6*(96))]
["depth_509", 512, 0.0005, 1e-15, 25, 'adamw', (4096, 8*(8,8),6*(96))]


# Going for this design now:
["depth_502", 512, 0.0001, 1e-21, 50, 'adamw', (512+128, 8*(8,8),3*(24,24,24,24))]
